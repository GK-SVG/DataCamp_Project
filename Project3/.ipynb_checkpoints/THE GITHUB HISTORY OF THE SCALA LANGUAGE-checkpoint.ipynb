{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scala's real-world project repository data\n",
    "<p>With almost 30k commits and a history spanning over ten years, Scala is a mature programming language. It is a general-purpose programming language that has recently become another prominent language for data scientists.</p>\n",
    "<p>Scala is also an open source project. Open source projects have the advantage that their entire development histories -- who made changes, what was changed, code reviews, etc. -- are publicly available. </p>\n",
    "<p>We're going to read in, clean up, and visualize the real world project repository of Scala that spans data from a version control system (Git) as well as a project hosting site (GitHub). We will find out who has had the most influence on its development and who are the experts.</p>\n",
    "<p>The dataset we will use, which has been previously mined and extracted from GitHub, is comprised of three files:</p>\n",
    "<ol>\n",
    "<li><code>pulls_2011-2013.csv</code> contains the basic information about the pull requests, and spans from the end of 2011 up to (but not including) 2014.</li>\n",
    "<li><code>pulls_2014-2018.csv</code> contains identical information, and spans from 2014 up to 2018.</li>\n",
    "<li><code>pull_files.csv</code> contains the files that were modified by each pull request.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "# ... YOUR CODE FOR TASK 1 ...\n",
    "import pandas as pd\n",
    "# Loading in the data\n",
    "pulls_one = pd.read_csv('datasets/pulls_2011-2013.csv')\n",
    "pulls_two = pd.read_csv('datasets/pulls_2014-2018.csv')\n",
    "pull_files = pd.read_csv('datasets/pull_files.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing and cleaning the data\n",
    "First, we will need to combine the data from the two separate pull DataFrames.\n",
    "\n",
    "Next, the raw data extracted from GitHub contains dates in the ISO8601 format. However, pandas imports them as regular strings. To make our analysis easier, we need to convert the strings into Python's DateTime objects. DateTime objects have the important property that they can be compared and sorted.\n",
    "\n",
    "The pull request times are all in UTC (also known as Coordinated Universal Time). The commit times, however, are in the local time of the author with time zone information (number of hours difference from UTC). To make comparisons easy, we should convert all times to UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append pulls_one to pulls_two\n",
    "pulls = pulls_one.append(pulls_two)\n",
    "\n",
    "# Convert the date for the pulls object\n",
    "pulls['date'] = pd.to_datetime(pulls['date'],utc=True)\n",
    "display(pulls.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merging the DataFrames\n",
    "The data extracted comes in two separate files. Merging the two DataFrames will make it easier for us to analyze the data in the future tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames\n",
    "display(pulls.head(10))\n",
    "display(pull_files.head(10))\n",
    "data = pulls.merge(pull_files,on='pid')\n",
    "display(data.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
